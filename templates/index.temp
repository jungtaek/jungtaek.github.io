            <p class="paragraph-120-bold">NEWS</p>

            <ul class="general-list no-bullet-list">

                <li>[October 2024] My collaborative paper "<a href="" target="_blank">Discovering Multi-Layer Films for Electromagnetic Interference Shielding and Passive Cooling with Multi-Objective Active Learning</a>" has been accepted at <a href="https://sites.google.com/view/ai4mat" target="_blank">NeurIPS Workshop on AI for Accelerated Materials Discovery (AI4Mat-2024)</a>.</li>
                <li>[September 2024] My paper "<a href="" target="_blank">Model Fusion through Bayesian Optimization in Language Model Fine-Tuning</a>" has been accepted at <a href="https://neurips.cc/Conferences/2024" target="_blank">NeurIPS-2024</a>.</li>
                <li>[September 2024] My paper "<a href="papers/tmlr_2024_a.pdf" target="_blank">Budget-Aware Sequential Brick Assembly with Efficient Constraint Satisfaction</a>" has been accepted at <a href="https://jmlr.org/tmlr/" target="_blank">TMLR</a>.</li>
                <li>[July 2024] My collaborative work "<a href="papers/cikm_2024.pdf" target="_blank">Exploiting Preferences in Loss Functions for Sequential Recommendation via Weak Transitivity</a>" has been accepted at <a href="https://cikm2024.org" target="_blank">CIKM-2024</a>.</li>
                <li>[May 2024] My work "<a href="https://arxiv.org/abs/2402.07341" target="_blank">Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization</a>" with Prof. <a href="https://kwangsungjun.github.io" target="_blank">Kwang-Sung Jun</a> has been accepted at <a href="https://icml.cc/Conferences/2024" target="_blank">ICML-2024</a>.</li>
                <li>[February 2024] My new paper "<a href="https://arxiv.org/abs/2402.07341" target="_blank">Noise-Adaptive Confidence Sets for Linear Bandits and Application to Bayesian Optimization</a>" has been released at <a href="https://arxiv.org" target="_blank">arXiv</a>.</li>

            </ul>

            <p class="paragraph-100 show-more"><a href="news.html">Show more</a></p>

            <hr>

            <p class="paragraph-120-bold">ABOUT ME</p>
            <p class="paragraph-100">
                Jungtaek Kim is a postdoctoral associate at the University of Pittsburgh, working as a member of the Center for Materials Data Science for Reliability and Degradation. At the University of Pittsburgh, he works with Prof. Paul W. Leu, Prof. Satish Iyengar, Prof. Lucas Mentch, and Prof. Oliver Hinder. Before that, he was a postdoctoral researcher at POSTECH, in the group of Prof. Minsu Cho. He received B.S. in Mechanical Engineering and Computer Science and Engineering from POSTECH in 2015, and Ph.D. in Computer Science and Engineering from POSTECH in 2022, under the supervision of Prof. Seungjin Choi and Prof. Minsu Cho. He interned at Vector Institute and SigOpt (acquired by Intel), during his Ph.D. program. His internship at Vector Institute was carried out under the supervision of Prof. Graham W. Taylor and he worked with Dr. Michael McCourt at SigOpt. He presented his work as the first author or a co-author, at the top-tier machine learning conferences such as NeurIPS, AISTATS, UAI, ICML, and ICLR, and moreover he served as a program committee member or a reviewer for diverse machine learning conferences such as NeurIPS, ICML, AISTATS, UAI, and ICLR. His main research interests are statistical machine learning, Bayesian optimization, and sequential assembly.
            </p>

            <hr>

            <p class="paragraph-120-bold">CURRENT RESEARCH INTERESTS</p>
            <ul class="general-list">
                <li>Statistical Machine Learning</li>
                <li>Bayesian Optimization</li>
                <li>Hyperparameter Optimization</li>
                <li>Automation of Machine Learning</li>
                <li>Sequential Assembly</li>
            </ul>

            <p class="paragraph-120-bold">WORK-IN-PROGRESS PAPERS</p>
            <ul class="general-list">
                <li>Jungtaek Kim. <a href="https://arxiv.org/abs/2401.01981" target="_blank">Beyond Regrets: Geometric Metrics for Bayesian Optimization</a>.</li>
                <li>Jungtaek Kim. <a href="https://arxiv.org/abs/2305.15612" target="_blank">Density Ratio Estimation-based Bayesian Optimization with Semi-Supervised Learning</a>.</li>
            </ul>

            <p class="paragraph-120-bold">ELSEWHERE</p>
            <ul class="general-list">
                <li>Academic Profile: <a href="https://scholar.google.com/citations?user=KXNUYWgAAAAJ" target="_blank">Google Scholar</a>, <a href="https://dblp.org/pid/31/3193-1" target="_blank">DBLP</a>, <a href="https://www.semanticscholar.org/author/2629559" target="_blank">Semantic Scholar</a>, <a href="https://orcid.org/0000-0002-1905-1399" target="_blank">ORCID</a></li>
                <li>Social Network: <a href="https://www.linkedin.com/in/jungtaekkim" target="_blank">LinkedIn</a>, <a href="https://x.com/jungtaek_kim" target="_blank">X</a></li>
                <li>Development: <a href="https://www.github.com/jungtaekkim" target="_blank">GitHub</a></li>
            </ul>
