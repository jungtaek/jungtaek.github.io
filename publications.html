<!DOCTYPE html>
<html>
    <head>
        <title>PUBLICATIONS | JUNGTAEK KIM</title>
        <link rel="stylesheet" type="text/css" href="mystyle.css">
    </head>
    <body>
        <div>
            <p class="paragraph-200-bold">Jungtaek Kim's Publications / E-prints / Manuscripts / Technical Reports / Dissertation</p>

            <p class="paragraph-100">(* and <sup>+</sup> indicate equal contribution by representing co-first and co-corresponding authors, respectively.)</p>

            <ol class="general-list">

                <!--icml-2025-b-->
                <li>
                    <strong>Jungtaek Kim</strong> (2025),<br>
                    <a href="papers/icml_2025_a.pdf">
                    "Density ratio estimation-based Bayesian optimization with semi-supervised learning,"</a><br>
                    in <i>Proceedings of the Forty-Second International Conference on Machine Learning (<strong>ICML-2025</strong>),</i><br>
                    Vancouver, British Columbia, Canada, July 13-19, 2025.<br>
                    Acceptance rate: 3260/12107 = 26.9%<br>
                </li>

                <!--icml-2025-a-->
                <li>
                    Thomas Zeng, Shuibai Zhang, Shutong Wu, Christian Classen, Daewon Chae, Ethan Ewer, Minjae Lee, Heeju Kim, Wonjun Kang, Jackson Kunde, Ying Fan, <strong>Jungtaek Kim</strong>, Hyung Il Koo, Kannan Ramchandran, Dimitris Papailiopoulos, and Kangwook Lee (2025),<br>
                    <a href="papers/icml_2025_b.pdf">
                    "VersaPRM: Multi-domain process reward model via synthetic reasoning data,"</a><br>
                    in <i>Proceedings of the Forty-Second International Conference on Machine Learning (<strong>ICML-2025</strong>),</i><br>
                    Vancouver, British Columbia, Canada, July 13-19, 2025.<br>
                    Acceptance rate: 3260/12107 = 26.9%<br>
                    Oral Presentation; Oral acceptance rate: 108/12107 = 0.9%<br>
<!--                    Spotlight Presentation; Spotlight acceptance rate: 313/12107 = 2.6%<br>-->
                </li>

                <!--ai4mat-2024-a-->
                <li>
                    Mingxuan Li, <strong>Jungtaek Kim</strong>, and Paul W. Leu (2024),<br>
                    <a href="papers/ai4mat_2024.pdf">
                        "Discovering multi-layer films for electromagnetic interference shielding and passive cooling with multi-objective active learning,"</a><br>
                    <i>NeurIPS Workshop on AI for Accelerated Materials Discovery (<strong>AI4Mat-2024</strong>),</i><br>
                    Vancouver, British Columbia, Canada, December 14, 2024.<br>
                </li>

                <!--neurips-2024-a-->
                <li>
                    Chaeyun Jang*, Hyungi Lee*, <strong>Jungtaek Kim</strong><sup>+</sup>, and Juho Lee<sup>+</sup> (2024),<br>
                    <a href="papers/neurips_2024.pdf">
                        "Model fusion through Bayesian optimization in language model fine-tuning,"</a><br>
                    in <i>Advances in Neural Information Processing Systems 37 (<strong>NeurIPS-2024</strong>),</i><br>
                    Vancouver, British Columbia, Canada, December 10-15, 2024.<br>
                    Acceptance rate: 4037/15671 = 25.8%<br>
                    Spotlight Presentation; Spotlight acceptance rate: 327/15671 = 2.1%<br>
                </li>

                <!--tmlr-2024-a-->
                <li>
                    Seokjun Ahn*, <strong>Jungtaek Kim</strong>*, Minsu Cho, and Jaesik Park (2024),<br>
                    <a href="papers/tmlr_2024_a.pdf">
                    "Budget-aware sequential brick assembly with efficient constraint satisfaction,"</a><br>
                    <i>Transactions on Machine Learning Research,</i><br>
                    2024.<br>
                </li>

                <!--cikm-2024-a-->
                <li>
                    Hyunsoo Chung, <strong>Jungtaek Kim</strong>, Hyungeun Jo, and Hyungwon Choi (2024),<br>
                    <a href="papers/cikm_2024.pdf">
                    "Exploiting preferences in loss functions for sequential recommendation via weak transitivity,"</a><br>
                    in <i>Proceedings of the Thirty-Third ACM International Conference on Information and Knowledge Management (<strong>CIKM-2024</strong>),</i><br>
                    Boise, Idaho, USA, October 21-25, 2024.<br>
                    Acceptance rate: 141/527 = 26.8%<br>
                    Short Research Paper Track<br>
                </li>

                <!--icml-2024-a-->
                <li>
                    Kwang-Sung Jun and <strong>Jungtaek Kim</strong> (2024),<br>
                    <a href="papers/icml_2024.pdf">
                    "Noise-adaptive confidence sets for linear bandits and application to Bayesian optimization,"</a><br>
                    in <i>Proceedings of the Forty-First International Conference on Machine Learning (<strong>ICML-2024</strong>),</i><br>
                    Vienna, Austria, July 21-27, 2024.<br>
                    Acceptance rate: 2610/9473 = 27.6%<br>
                </li>

                <!--se-2024-a-->
                <li>
                    Karinna Martin, Katie Shanks, Yipeng Liu, <strong>Jungtaek Kim</strong>, Sajad Haghanifar, Mehdi Zarei, Sooraj Sharma, and Paul W. Leu (2024),<br>
                    <a href="https://doi.org/10.1016/j.solener.2024.112424">
                        "Minimizing annual reflection loss in fixed-tilt photovoltaic modules using graded refractive index (GRIN) anti-reflective glass,"</a><br>
                    <i>Solar Energy,</i><br>
                    vol. 272, p. 112424, 2024.<br>
                </li>

                <!--acsami-2024-a-->
                <li>
                    Mehdi Zarei, Mingxuan Li, Elizabeth E. Medvedeva, Sooraj Sharma, <strong>Jungtaek Kim</strong>, Zefan Shao, S. Brett Walker, Melbs LeMieux, Qihan Liu, and Paul W. Leu (2024),<br>
                    <a href="https://doi.org/10.1021/acsami.3c16405">
                        "Flexible embedded metal meshes by sputter-free crack lithography for transparent electrodes and electromagnetic interference shielding,"</a><br>
                    <i>ACS Applied Materials & Interfaces,</i><br>
                    vol. 16, no. 5, pp. 6382-6393, 2024.<br>
                </li>

                <!--iclr-2024-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Jeongbeen Yoon, and Minsu Cho (2024),<br>
                    <a href="papers/iclr_2024.pdf">
                        "Generalized neural sorting networks with error-free differentiable swap functions,"</a><br>
                    in <i>Proceedings of the Twelfth International Conference on Learning Representations (<strong>ICLR-2024</strong>),</i><br>
                    Vienna, Austria, May 7-11, 2024.<br>
                    Acceptance rate: 2260/7262 = 31.1%<br>
                </li>

                <!--dd-2024-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Mingxuan Li, Yirong Li, Andrés Gómez, Oliver Hinder, and Paul W. Leu (2024),<br>
                    <a href="https://doi.org/10.1039/D3DD00177F">
                        "Multi-BOWS: Multi-fidelity multi-objective Bayesian optimization with warm starts for nanophotonic structure design,"</a><br>
                    <i>Digital Discovery,</i><br>
                    vol. 3, no. 2, pp. 381-391, 2024.<br>
                </li>

                <!--enlsp-2023-a-->
                <li>
                    Chaeyun Jang, <strong>Jungtaek Kim</strong>, Hyungi Lee, and Juho Lee (2023),<br>
                    <a href="papers/enlsp_2023.pdf">
                        "Model fusion through Bayesian optimization in language model fine-tuning,"</a><br>
                    <i>NeurIPS Workshop on Efficient Natural Language and Speech Processing (<strong>ENLSP-2023</strong>),</i><br>
                    New Orleans, Louisiana, USA, December 16, 2023.<br>
                </li>

                <!--ssl-tp-2023-a-->
                <li>
                    Hyunsoo Chung and <strong>Jungtaek Kim</strong> (2023),<br>
                    <a href="papers/ssl_tp_2023.pdf">
                        "Leveraging uniformity of normalized embeddings for sequential recommendation,"</a><br>
                    <i>NeurIPS Workshop on Self-Supervised Learning - Theory and Practice (<strong>SSL-TP-2023</strong>),</i><br>
                    New Orleans, Louisiana, USA, December 16, 2023.<br>
                </li>

                <!--joss-2023-a-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2023),<br>
                    <a href="https://doi.org/10.21105/joss.05320">
                        "BayesO: A Bayesian optimization framework in Python,"</a><br>
                    <i>Journal of Open Source Software,</i><br>
                    vol. 8, no. 90, p. 5320, 2023.<br>
                </li>

                <!--neurips-2023-b-->
                <li>
                    <strong>Jungtaek Kim</strong>, Mingxuan Li, Oliver Hinder, and Paul W. Leu (2023),<br>
                    <a href="papers/neurips_2023_db.pdf">
                        "Datasets and benchmarks for nanophotonic structure and parametric design simulations,"</a><br>
                    in <i>Advances in Neural Information Processing Systems 36 (<strong>NeurIPS-2023</strong>),</i><br>
                    New Orleans, Louisiana, USA, December 10-16, 2023.<br>
                    Acceptance rate: 322/987 = 32.6%<br>
                    Datasets and Benchmarks Track<br>
                </li>

                <!--neurips-2023-a-->
                <li>
                    Tackgeun You, Mijeong Kim, <strong>Jungtaek Kim</strong>, and Bohyung Han (2023),<br>
                    <a href="papers/neurips_2023.pdf">
                        "Generative neural fields by mixtures of neural implicit functions,"</a><br>
                    in <i>Advances in Neural Information Processing Systems 36 (<strong>NeurIPS-2023</strong>),</i><br>
                    New Orleans, Louisiana, USA, December 10-16, 2023.<br>
                    Acceptance rate: 3218/12343 = 26.1%<br>
                </li>

                <!--uai-2022-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Seungjin Choi<sup>+</sup>, and Minsu Cho<sup>+</sup> (2022),<br>
                    <a href="papers/uai_2022.pdf">
                        "Combinatorial Bayesian optimization with random mapping functions to convex polytopes,"</a><br>
                    in <i>Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence (<strong>UAI-2022</strong>),</i><br>
                    Eindhoven, the Netherlands, August 1-5, 2022.<br>
                    Acceptance rate: 230/712 = 32.3%<br>
                </li>

                <!--ijcai-ecai-2022-a-->
                <li>
                    Jinhwi Lee*, <strong>Jungtaek Kim</strong>*, Hyunsoo Chung, Jaesik Park, and Minsu Cho (2022),<br>
                    <a href="papers/ijcai_2022.pdf">
                        "Learning to assemble geometric shapes,"</a><br>
                    in <i>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence (<strong>IJCAI-2022</strong>),</i><br>
                    Vienna, Austria, July 23-29, 2022.<br>
                    Acceptance rate: 681/4535 = 15.0%<br>
                </li>

                <!--iclr-2022-a-->
                <li>
                    Rylee Thompson, Boris Knyazev, Elahe Ghalebi, <strong>Jungtaek Kim</strong>, and Graham W. Taylor (2022),<br>
                    <a href="papers/iclr_2022.pdf">
                        "On evaluation metrics for graph generative models,"</a><br>
                    in <i>Proceedings of the Tenth International Conference on Learning Representations (<strong>ICLR-2022</strong>),</i><br>
                    Virtual, April 25-29, 2022.<br>
                    Acceptance rate: 1095/3391 = 32.3%<br>
                </li>

                <!--aistats-2022-a-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2022),<br>
                    <a href="papers/aistats_2022.pdf">
                        "On uncertainty estimation by tree-based surrogate models in sequential model-based optimization,"</a><br>
                    in <i>Proceedings of the Twenty-Fifth International Conference on Artificial Intelligence and Statistics (<strong>AISTATS-2022</strong>),</i><br>
                    Virtual, March 28-30, 2022.<br>
                    Acceptance rate: 492/1685 = 29.2%<br>
                </li>

                <!--thesis-2022-->
                <li>
                    <strong>Jungtaek Kim</strong> (2022),<br>
                    <a href="">
                        "Efficient Bayesian optimization: Algorithms, approximation, and regret analysis,"</a><br>
                    <i>Doctoral Dissertation,</i><br>
                    2022.<br>
                </li>

                <!--neurips-2021-a-->
                <li>
                    Hyunsoo Chung*, <strong>Jungtaek Kim</strong>*, Boris Knyazev, Jinhwi Lee, Graham W. Taylor, Jaesik Park, and Minsu Cho (2021),<br>
                    <a href="papers/neurips_2021.pdf">
                        "Brick-by-Brick: Combinatorial construction with deep reinforcement learning,"</a><br>
                    in <i>Advances in Neural Information Processing Systems 34 (<strong>NeurIPS-2021</strong>),</i><br>
                    Virtual, December 6-14, 2021.<br>
                    Acceptance rate: 2344/9122 = 25.7%<br>
                </li>

                <!--ml-2021-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Michael McCourt, Tackgeun You, Saehoon Kim, and Seungjin Choi (2021),<br>
                    <a href="https://doi.org/10.1007/s10994-021-05949-0">
                        "Bayesian optimization with approximate set kernels,"</a><br>
                    <i>Machine Learning,</i><br>
                    vol. 110, no. 5, pp. 857-879, 2021.<br>
                    Acceptance rate: 20/107 = 18.7%<br>
                    Part of Special Issue of the ECML-PKDD-2021 Journal Track<br>
                </li>

                <!--ml4eng-2020-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Hyunsoo Chung, Jinhwi Lee, Minsu Cho, and Jaesik Park (2020),<br>
                    <a href="papers/ml4eng_2020.pdf">
                        "Combinatorial 3D shape generation via sequential assembly,"</a><br>
                    <i>NeurIPS Workshop on Machine Learning for Engineering Modeling, Simulation, and Design (<strong>ML4Eng-2020</strong>),</i><br>
                    Virtual, December 12, 2020.<br>
                </li>

                <!--lmca-2020-a-->
                <li>
                    Jinhwi Lee*, <strong>Jungtaek Kim</strong>*, Hyunsoo Chung, Jaesik Park, and Minsu Cho (2020),<br>
                    <a href="papers/lmca_2020.pdf">
                        "Fragment relation networks for geometric shape assembly,"</a><br>
                    <i>NeurIPS Workshop on Learning Meets Combinatorial Algorithms (<strong>LMCA-2020</strong>),</i><br>
                    Virtual, December 12, 2020.<br>
                </li>

                <!--neurips-2020-a-->
                <li>
                    Juho Lee*, Yoonho Lee*, <strong>Jungtaek Kim</strong>, Eunho Yang, Sung Ju Hwang, and Yee Whye Teh (2020),<br>
                    <a href="papers/neurips_2020.pdf">
                        "Bootstrapping neural processes,"</a><br>
                    in <i>Advances in Neural Information Processing Systems 33 (<strong>NeurIPS-2020</strong>),</i><br>
                    Virtual, December 6-12, 2020.<br>
<!--                    Vancouver, British Columbia, Canada, December 6-12, 2020.<br>-->
                    Acceptance rate: 1900/9454 = 20.1%<br>
                </li>

                <!--ecml-pkdd-2020-a-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2020),<br>
                    <a href="papers/ecmlpkdd_2020.pdf">
                        "On local optimizers of acquisition functions in Bayesian optimization,"</a><br>
                    in <i>Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (<strong>ECML-PKDD-2020</strong>),</i><br>
                    Virtual, September 14-18, 2020.<br>
<!--                    Ghent, Belgium, September 14-18, 2020.<br>-->
                    Acceptance rate: 131/687 = 19.1%<br>
                </li>

                <!--notes-2020-a-->
                <li>
                    <strong>Jungtaek Kim</strong> (2020),<br>
                    <a href="notes/benchmarks_bo.pdf">
                        "Benchmark functions for Bayesian optimization,"</a><br>
                    <i>Notes on Bayesian Optimization,</i><br>
                    July 30, 2020.<br>
                </li>

                <!--automl-2019-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Michael McCourt, Tackgeun You, Saehoon Kim, and Seungjin Choi (2019),<br>
                    <a href="papers/automl_2019.pdf">
                        "Bayesian optimization over sets,"</a><br>
                    <i>ICML Workshop on Automated Machine Learning (<strong>AutoML-2019</strong>),</i><br>
                    Long Beach, California, USA, June 14, 2019.<br>
                </li>

                <!--icml-2019-a-->
                <li>
                    Juho Lee, Yoonho Lee, <strong>Jungtaek Kim</strong>, Adam R. Kosiorek, Seungjin Choi, and Yee Whye Teh (2019),<br>
                    <a href="papers/icml_2019.pdf">
                    "Set Transformer: A framework for attention-based permutation-invariant neural networks,"</a><br>
                    in <i>Proceedings of the Thirty-Sixth International Conference on Machine Learning (<strong>ICML-2019</strong>),</i><br>
                    Long Beach, California, USA, June 9-15, 2019.<br>
                    Acceptance rate: 773/3424 = 22.6%<br>
                </li>

                <!--arxiv-1904.05658-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2019),<br>
                    <a href="https://arxiv.org/pdf/1905.07540.pdf">
                        "Practical Bayesian optimization with threshold-guided marginal likelihood maximization,"</a><br>
                    <i>arXiv e-prints</i>, arXiv:1905.07540, May 18, 2019.<br>
                </li>

                <!--arxiv-1904.05658-->
                <li>
                    Minseop Park, <strong>Jungtaek Kim</strong>, Saehoon Kim, Yanbin Liu, and Seungjin Choi (2019),<br>
                    <a href="https://arxiv.org/pdf/1904.05658.pdf">
                        "MxML: Mixture of meta-learners for few-shot classification,"</a><br>
                    <i>arXiv e-prints</i>, arXiv:1904.05658, April 11, 2019.<br>
                </li>

                <!--metalearn-2018-a-->
                <li>
                    Minseop Park, Saehoon Kim, <strong>Jungtaek Kim</strong>, Yanbin Liu, and Seungjin Choi (2018),<br>
                    <a href="papers/metalearn_2018.pdf">
                        "TAEML: Task-adaptive ensemble of meta-learners,"</a><br>
                    <i>NeurIPS Workshop on Meta-Learning (<strong>MetaLearn-2018</strong>),</i><br>
                    Montreal, Quebec, Canada, December 8, 2018.<br>
                </li>

                <!--automl-2018-a-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2018),<br>
                    <a href="papers/automl_2018.pdf">
                        "Automated machine learning for soft voting in an ensemble of tree-based classifiers,"</a><br>
                    <i>ICML Workshop on Automatic Machine Learning (<strong>AutoML-2018</strong>),</i><br>
                    Stockholm, Sweden, July 14, 2018.<br>
                </li>

                <!--icassp-2018-b-->
                <li>
                    Inhyuk Jo, <strong>Jungtaek Kim</strong>, Hyohyeong Kang, Yong-Deok Kim, and Seungjin Choi (2018),<br>
                    <a href="papers/icassp_2018_b.pdf">
                        "Open set recognition by regularizing classifier with fake data generated by generative adversarial networks,"</a><br>
                    in <i>Proceedings of the Forty-Third IEEE International Conference on Acoustics, Speech, and Signal Processing (<strong>ICASSP-2018</strong>),</i><br>
                    Calgary, Alberta, Canada, April 15-20, 2018.<br>
                    Acceptance rate: 1406/2829 = 49.7%<br>
                </li>

                <!--icassp-2018-a-->
                <li>
                    <strong>Jungtaek Kim</strong> and Seungjin Choi (2018),<br>
                    <a href="papers/icassp_2018_a.pdf">
                        "Clustering-guided GP-UCB for Bayesian optimization,"</a><br>
                    in <i>Proceedings of the Forty-Third IEEE International Conference on Acoustics, Speech, and Signal Processing (<strong>ICASSP-2018</strong>),</i><br>
                    Calgary, Alberta, Canada, April 15-20, 2018.<br>
                    Acceptance rate: 1406/2829 = 49.7%<br>
                </li>

                <!--aaai-2018-a-->
                <li>
                    Saehoon Kim, <strong>Jungtaek Kim</strong>, and Seungjin Choi (2018),<br>
                    <a href="papers/aaai_2018.pdf">
                        "On the optimal bit complexity of circulant binary embedding,"</a><br>
                    in <i>Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (<strong>AAAI-2018</strong>),</i><br>
                    New Orleans, Louisiana, USA, February 2-7, 2018.<br>
                    Acceptance rate: 933/3800 = 24.6%<br>
                </li>

                <!--bayesopt-2017-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Saehoon Kim, and Seungjin Choi (2017),<br>
                    <a href="papers/bayesopt_2017.pdf">
                        "Learning to transfer initializations for Bayesian hyperparameter optimization,"</a><br>
                    <i>NeurIPS Workshop on Bayesian Optimization (<strong>BayesOpt-2017</strong>),</i><br>
                    Long Beach, California, USA, December 9, 2017.<br>
                </li>

                <!--arxiv-1710.06219-->
                <li>
                    <strong>Jungtaek Kim</strong>, Saehoon Kim, and Seungjin Choi (2017),<br>
                    <a href="https://arxiv.org/pdf/1710.06219.pdf">
                        "Learning to warm-start Bayesian hyperparameter optimization,"</a><br>
                    <i>arXiv e-prints</i>, arXiv:1710.06219, October 17, 2017.<br>
                </li>

                <!--automl-2016-a-->
                <li>
                    <strong>Jungtaek Kim</strong>, Jongheon Jeong, and Seungjin Choi (2016),<br>
                    <a href="papers/automl_2016.pdf">
                        "AutoML Challenge: AutoML framework using random space partitioning optimizer,"</a><br>
                    <i>ICML Workshop on Automatic Machine Learning (<strong>AutoML-2016</strong>),</i><br>
                    New York, New York, USA, June 24, 2016.<br>
                    Special Track, 3-page<br>
                </li>

            </ol>
        </div>
    </body>
</html>
